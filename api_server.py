"""
VoxCPM API Server for Legado Reader
ä¸º Legado é˜…è¯»å™¨æä¾›è‡ªå®šä¹‰æœ—è¯»å¼•æ“çš„ HTTP API æœåŠ¡
"""
import os
import io
import json
import logging
import tempfile
from pathlib import Path
from typing import Optional
import numpy as np
import torch
import soundfile as sf
from fastapi import FastAPI, HTTPException, Request, UploadFile, File, Form
from fastapi.responses import Response, StreamingResponse
from pydantic import BaseModel
import uvicorn

# æŠ‘åˆ¶ ModelScope çš„è­¦å‘Šä¿¡æ¯
logging.getLogger('modelscope').setLevel(logging.ERROR)

# è®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•åˆ°é¡¹ç›®ç›®å½•
PROJECT_ROOT = Path(__file__).parent.absolute()
MODELS_CACHE_DIR = PROJECT_ROOT / "models_cache"

# è®¾ç½® HuggingFace ç¼“å­˜ç›®å½•
os.environ["HF_HOME"] = str(MODELS_CACHE_DIR / "huggingface")
os.environ["HF_HUB_CACHE"] = str(MODELS_CACHE_DIR / "huggingface" / "hub")

# è®¾ç½® ModelScope ç¼“å­˜ç›®å½•
os.environ["MODELSCOPE_CACHE"] = str(MODELS_CACHE_DIR / "modelscope" / "hub")

os.environ["TOKENIZERS_PARALLELISM"] = "false"
if os.environ.get("HF_REPO_ID", "").strip() == "":
    os.environ["HF_REPO_ID"] = "openbmb/VoxCPM1.5"

import voxcpm

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(title="VoxCPM TTS API", description="VoxCPM Text-to-Speech API for Legado Reader")

# å…¨å±€æ¨¡å‹å®ä¾‹
voxcpm_model: Optional[voxcpm.VoxCPM] = None


class TTSRequest(BaseModel):
    """TTS è¯·æ±‚æ¨¡å‹ï¼ˆJSONæ ¼å¼ï¼‰"""
    text: str
    voice: Optional[str] = None  # é¢„ç•™ï¼Œç”¨äºæœªæ¥æ”¯æŒå¤šéŸ³è‰²
    speed: Optional[float] = 1.0  # é¢„ç•™ï¼Œç”¨äºæœªæ¥æ”¯æŒè¯­é€Ÿæ§åˆ¶
    pitch: Optional[float] = 1.0  # é¢„ç•™ï¼Œç”¨äºæœªæ¥æ”¯æŒéŸ³è°ƒæ§åˆ¶
    cfg_value: Optional[float] = 2.0  # CFG å€¼
    inference_timesteps: Optional[int] = 10  # æ¨ç†æ—¶é—´æ­¥
    normalize: Optional[bool] = False  # æ–‡æœ¬æ­£åˆ™åŒ–
    denoise: Optional[bool] = False  # éŸ³é¢‘é™å™ª
    prompt_wav_path: Optional[str] = None  # å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆæœåŠ¡å™¨æœ¬åœ°è·¯å¾„ï¼‰
    prompt_text: Optional[str] = None  # å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬


def _resolve_model_dir() -> str:
    """
    è§£ææ¨¡å‹ç›®å½•:
    1) å¦‚æœæœ¬åœ°æ£€æŸ¥ç‚¹ç›®å½•å­˜åœ¨ï¼Œä½¿ç”¨æœ¬åœ°ç›®å½•
    2) å¦‚æœè®¾ç½®äº† HF_REPO_ID ç¯å¢ƒå˜é‡ï¼Œä¸‹è½½åˆ° models/{repo}
    3) å¦åˆ™å›é€€åˆ° 'models'
    """
    default_local_model_dir = "./models/openbmb__VoxCPM1.5"
    if os.path.isdir(default_local_model_dir):
        return default_local_model_dir
    
    repo_id = os.environ.get("HF_REPO_ID", "").strip()
    if len(repo_id) > 0:
        target_dir = os.path.join("models", repo_id.replace("/", "__"))
        if not os.path.isdir(target_dir):
            try:
                from huggingface_hub import snapshot_download
                os.makedirs(target_dir, exist_ok=True)
                print(f"æ­£åœ¨ä» HuggingFace ä¸‹è½½æ¨¡å‹ '{repo_id}' åˆ° '{target_dir}' ...")
                snapshot_download(repo_id=repo_id, local_dir=target_dir, local_dir_use_symlinks=False)
            except Exception as e:
                print(f"è­¦å‘Š: HuggingFace ä¸‹è½½å¤±è´¥: {e}. å›é€€åˆ°ç¼“å­˜ç›®å½•ã€‚")
                return None  # è¿”å› None è¡¨ç¤ºéœ€è¦ä½¿ç”¨ from_pretrained
        return target_dir
    return None


def get_or_load_model() -> voxcpm.VoxCPM:
    """è·å–æˆ–åŠ è½½ VoxCPM æ¨¡å‹"""
    global voxcpm_model
    if voxcpm_model is not None:
        return voxcpm_model
    
    print("æ­£åœ¨åŠ è½½ VoxCPM æ¨¡å‹...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"ğŸš€ è¿è¡Œè®¾å¤‡: {device}")
    
    # è§£ææ¨¡å‹ç›®å½•
    model_dir = _resolve_model_dir()
    
    # å¦‚æœæœ¬åœ°ç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨ from_pretrained ä¸‹è½½åˆ°é¡¹ç›®ç¼“å­˜ç›®å½•
    if model_dir is None or not os.path.isdir(model_dir):
        print("æ­£åœ¨ä¸‹è½½æ¨¡å‹åˆ°é¡¹ç›®ç¼“å­˜ç›®å½•...")
        repo_id = os.environ.get("HF_REPO_ID", "openbmb/VoxCPM1.5")
        cache_dir = str(MODELS_CACHE_DIR / "huggingface" / "hub")
        voxcpm_model = voxcpm.VoxCPM.from_pretrained(
            hf_model_id=repo_id,
            cache_dir=cache_dir,
            optimize=False,  # ç¦ç”¨ä¼˜åŒ–ä»¥é¿å…å¤šçº¿ç¨‹é—®é¢˜
        )
    else:
        print(f"ä½¿ç”¨æ¨¡å‹ç›®å½•: {model_dir}")
        voxcpm_model = voxcpm.VoxCPM(
            voxcpm_model_path=model_dir,
            optimize=False,  # ç¦ç”¨ä¼˜åŒ–ä»¥é¿å…å¤šçº¿ç¨‹é—®é¢˜
        )
    
    print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    return voxcpm_model


@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶é¢„åŠ è½½æ¨¡å‹"""
    print("æ­£åœ¨åˆå§‹åŒ– VoxCPM API æœåŠ¡...")
    get_or_load_model()
    print("API æœåŠ¡å·²å°±ç»ªï¼")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å› API ä¿¡æ¯"""
    return {
        "name": "VoxCPM TTS API",
        "version": "1.0.0",
        "description": "VoxCPM Text-to-Speech API for Legado Reader",
        "endpoints": {
            "/tts": "POST - æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆJSONæ ¼å¼ï¼Œæ”¯æŒå‚è€ƒéŸ³é¢‘è·¯å¾„ï¼‰ã€‚æ·»åŠ  ?stream=true å¯ç”¨æµå¼è¾“å‡º",
            "/tts/upload": "POST - æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆmultipart/form-dataï¼Œæ”¯æŒä¸Šä¼ å‚è€ƒéŸ³é¢‘ï¼‰",
            "/tts/stream": "POST - æµå¼æ–‡æœ¬è½¬è¯­éŸ³ï¼ˆPCMæ ¼å¼ï¼Œé€‚åˆé•¿æ–‡æœ¬ï¼‰",
            "/health": "GET - å¥åº·æ£€æŸ¥"
        }
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    model = get_or_load_model()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return {
        "status": "healthy",
        "model_loaded": model is not None,
        "device": device,
        "sample_rate": model.tts_model.sample_rate if model else None
    }


@app.get("/tts")
async def text_to_speech_get():
    """
    GET ç«¯ç‚¹ç”¨äºæµ‹è¯•è¿æ¥
    Legado å¯èƒ½ä¼šå…ˆå‘é€ GET è¯·æ±‚æµ‹è¯•è¿æ¥
    """
    return {
        "status": "ok",
        "message": "VoxCPM TTS API is running. Please use POST method for TTS requests.",
        "endpoint": "/tts",
        "method": "POST",
        "content_type": "application/json"
    }


@app.post("/tts")
async def text_to_speech(request: Request):
    """
    æ–‡æœ¬è½¬è¯­éŸ³ç«¯ç‚¹ï¼ˆJSONæ ¼å¼ï¼‰
    æ”¯æŒ Legado é˜…è¯»å™¨çš„ httpTTS API æ ¼å¼
    æ”¯æŒå£°éŸ³å…‹éš†ï¼šé€šè¿‡ prompt_wav_path å’Œ prompt_text å‚æ•°
    æ”¯æŒæµå¼è¾“å‡ºï¼šé€šè¿‡æŸ¥è¯¢å‚æ•° ?stream=true
    """
    try:
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º
        stream_mode = request.query_params.get("stream", "false").lower() == "true"
        
        # è®°å½•è¯·æ±‚ä¿¡æ¯ç”¨äºè°ƒè¯•
        print(f"\n{'='*60}")
        print(f"æ”¶åˆ° POST è¯·æ±‚: {request.url}")
        print(f"è¯·æ±‚æ–¹æ³•: {request.method}")
        print(f"æµå¼æ¨¡å¼: {stream_mode}")
        print(f"è¯·æ±‚å¤´: {dict(request.headers)}")
        
        # è¯»å–è¯·æ±‚ä½“
        try:
            body_bytes = await request.body()
            body_str = body_bytes.decode('utf-8')
            print(f"åŸå§‹è¯·æ±‚ä½“: {body_str[:500]}")
            
            # è§£æ JSON
            body_json = json.loads(body_str)
            print(f"è§£æçš„ JSON: {body_json}")
            
            # åˆ›å»ºè¯·æ±‚å¯¹è±¡
            tts_request = TTSRequest(**body_json)
        except json.JSONDecodeError as e:
            print(f"JSON è§£æé”™è¯¯: {e}")
            print(f"è¯·æ±‚ä½“å†…å®¹: {body_str if 'body_str' in locals() else 'æ— æ³•è¯»å–'}")
            raise HTTPException(status_code=400, detail=f"JSON æ ¼å¼é”™è¯¯: {str(e)}")
        except Exception as e:
            print(f"è§£æè¯·æ±‚ä½“å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=400, detail=f"è¯·æ±‚ä½“æ ¼å¼é”™è¯¯: {str(e)}")
        
        # è·å–æ¨¡å‹
        model = get_or_load_model()
        
        # éªŒè¯æ–‡æœ¬
        text = (tts_request.text or "").strip()
        
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ”¶åˆ°çš„æ˜¯å ä½ç¬¦å­—é¢é‡ï¼Œå°è¯•ä»è¯·æ±‚ä¸­è·å–
        if text in ["content", "{content}", "{{speakText}}", "{{content}}"]:
            print(f"âš ï¸  æ£€æµ‹åˆ°å ä½ç¬¦å­—é¢é‡: {text}")
            # å°è¯•ä»è¯·æ±‚å¤´æˆ–å…¶ä»–åœ°æ–¹è·å–å®é™…æ–‡æœ¬
            # æ³¨æ„ï¼šè¿™å¯èƒ½éœ€è¦ Legado çš„ç‰¹æ®Šæ”¯æŒ
            raise HTTPException(
                status_code=400, 
                detail=f"å ä½ç¬¦æœªè¢«æ›¿æ¢ï¼Œæ”¶åˆ°: {text}ã€‚è¯·æ£€æŸ¥ Legado é…ç½®ä¸­çš„å ä½ç¬¦æ ¼å¼ã€‚å¯¹äº JSON bodyï¼Œåº”ä½¿ç”¨ {{speakText}} æˆ– {{content}}"
            )
        
        if len(text) == 0:
            raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # éªŒè¯å‚è€ƒéŸ³é¢‘å‚æ•°
        prompt_wav_path = tts_request.prompt_wav_path
        prompt_text = tts_request.prompt_text
        
        if (prompt_wav_path is not None) != (prompt_text is not None):
            raise HTTPException(
                status_code=400, 
                detail="å‚è€ƒéŸ³é¢‘å’Œå‚è€ƒæ–‡æœ¬å¿…é¡»åŒæ—¶æä¾›æˆ–åŒæ—¶ä¸ºç©º"
            )
        
        # å¦‚æœæä¾›äº†å‚è€ƒéŸ³é¢‘è·¯å¾„ï¼ŒéªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if prompt_wav_path:
            if not os.path.exists(prompt_wav_path):
                raise HTTPException(
                    status_code=400,
                    detail=f"å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {prompt_wav_path}"
                )
            print(f"ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œå£°éŸ³å…‹éš†: {prompt_wav_path}")
            print(f"å‚è€ƒæ–‡æœ¬: '{prompt_text[:60]}...'")
        else:
            print(f"æ ‡å‡†è¯­éŸ³åˆæˆï¼Œæ–‡æœ¬: '{text[:60]}...'")
        
        # è·å–é‡‡æ ·ç‡
        sample_rate = model.tts_model.sample_rate
        
        # æµå¼è¾“å‡ºæ¨¡å¼
        if stream_mode:
            def generate_audio_stream():
                try:
                    for chunk in model.generate_streaming(
                        text=text,
                        prompt_text=prompt_text,
                        prompt_wav_path=prompt_wav_path,
                        cfg_value=tts_request.cfg_value or 2.0,
                        inference_timesteps=tts_request.inference_timesteps or 10,
                        normalize=tts_request.normalize or False,
                        denoise=tts_request.denoise or False,
                    ):
                        # å°†éŸ³é¢‘å—è½¬æ¢ä¸º 16-bit PCM æ ¼å¼
                        chunk_int16 = (chunk * 32767).astype(np.int16)
                        chunk_bytes = chunk_int16.tobytes()
                        yield chunk_bytes
                except Exception as e:
                    logging.error(f"æµå¼ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
                    raise
            
            return StreamingResponse(
                generate_audio_stream(),
                media_type="audio/pcm",
                headers={
                    "Content-Type": f"audio/pcm; rate={sample_rate}; channels=1; encoding=pcm_s16le",
                    "X-Sample-Rate": str(sample_rate),
                    "X-Channels": "1",
                    "X-Encoding": "pcm_s16le",
                }
            )
        
        # éæµå¼è¾“å‡ºæ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
        # ç”Ÿæˆè¯­éŸ³
        wav = model.generate(
            text=text,
            prompt_text=prompt_text,
            prompt_wav_path=prompt_wav_path,
            cfg_value=tts_request.cfg_value or 2.0,
            inference_timesteps=tts_request.inference_timesteps or 10,
            normalize=tts_request.normalize or False,
            denoise=tts_request.denoise or False,
        )
        
        # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º WAV æ ¼å¼çš„å­—èŠ‚æµ
        buffer = io.BytesIO()
        sf.write(buffer, wav, sample_rate, format='WAV')
        buffer.seek(0)
        
        # è¿”å›éŸ³é¢‘æ–‡ä»¶
        return Response(
            content=buffer.read(),
            media_type="audio/wav",
            headers={
                "Content-Disposition": "attachment; filename=tts_output.wav"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"ç”Ÿæˆè¯­éŸ³æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆè¯­éŸ³å¤±è´¥: {str(e)}")


@app.post("/tts/upload")
async def text_to_speech_with_upload(
    text: str = Form(...),
    prompt_audio: Optional[UploadFile] = File(None),
    prompt_text: Optional[str] = Form(None),
    cfg_value: float = Form(2.0),
    inference_timesteps: int = Form(10),
    normalize: bool = Form(False),
    denoise: bool = Form(False),
):
    """
    æ–‡æœ¬è½¬è¯­éŸ³ç«¯ç‚¹ï¼ˆæ”¯æŒä¸Šä¼ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ï¼‰
    ä½¿ç”¨ multipart/form-data æ ¼å¼
    é€‚åˆéœ€è¦ä¸Šä¼ å‚è€ƒéŸ³é¢‘è¿›è¡Œå£°éŸ³å…‹éš†çš„åœºæ™¯
    """
    try:
        # è·å–æ¨¡å‹
        model = get_or_load_model()
        
        # éªŒè¯æ–‡æœ¬
        text = (text or "").strip()
        if len(text) == 0:
            raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # å¤„ç†å‚è€ƒéŸ³é¢‘
        prompt_wav_path = None
        temp_file = None
        
        if prompt_audio is not None:
            # éªŒè¯å‚è€ƒæ–‡æœ¬
            if not prompt_text:
                raise HTTPException(
                    status_code=400,
                    detail="ä¸Šä¼ å‚è€ƒéŸ³é¢‘æ—¶å¿…é¡»æä¾›å¯¹åº”çš„å‚è€ƒæ–‡æœ¬ (prompt_text)"
                )
            
            # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
            try:
                content = await prompt_audio.read()
                temp_file.write(content)
                temp_file.close()
                prompt_wav_path = temp_file.name
                
                print(f"ä½¿ç”¨ä¸Šä¼ çš„å‚è€ƒéŸ³é¢‘è¿›è¡Œå£°éŸ³å…‹éš†: {prompt_wav_path}")
                print(f"å‚è€ƒæ–‡æœ¬: '{prompt_text[:60]}...'")
            except Exception as e:
                if temp_file:
                    os.unlink(temp_file.name)
                raise HTTPException(status_code=400, detail=f"è¯»å–éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
        else:
            print(f"æ ‡å‡†è¯­éŸ³åˆæˆï¼Œæ–‡æœ¬: '{text[:60]}...'")
        
        try:
            # ç”Ÿæˆè¯­éŸ³
            wav = model.generate(
                text=text,
                prompt_text=prompt_text if prompt_audio else None,
                prompt_wav_path=prompt_wav_path,
                cfg_value=cfg_value,
                inference_timesteps=inference_timesteps,
                normalize=normalize,
                denoise=denoise,
            )
            
            # è·å–é‡‡æ ·ç‡
            sample_rate = model.tts_model.sample_rate
            
            # å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸º WAV æ ¼å¼çš„å­—èŠ‚æµ
            buffer = io.BytesIO()
            sf.write(buffer, wav, sample_rate, format='WAV')
            buffer.seek(0)
            
            return Response(
                content=buffer.read(),
                media_type="audio/wav",
                headers={
                    "Content-Disposition": "attachment; filename=tts_output.wav"
                }
            )
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_file and os.path.exists(temp_file.name):
                os.unlink(temp_file.name)
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"ç”Ÿæˆè¯­éŸ³æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆè¯­éŸ³å¤±è´¥: {str(e)}")


@app.post("/tts/stream")
async def text_to_speech_stream(request: TTSRequest):
    """
    æµå¼æ–‡æœ¬è½¬è¯­éŸ³ç«¯ç‚¹
    æ”¯æŒæµå¼ç”Ÿæˆï¼Œé€‚åˆé•¿æ–‡æœ¬
    è¿”å›æ ¼å¼ï¼šPCM éŸ³é¢‘æµï¼ˆ16-bit, å•å£°é“ï¼‰
    """
    try:
        # è·å–æ¨¡å‹
        model = get_or_load_model()
        
        # éªŒè¯æ–‡æœ¬
        text = (request.text or "").strip()
        if len(text) == 0:
            raise HTTPException(status_code=400, detail="æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º")
        
        # éªŒè¯å‚è€ƒéŸ³é¢‘å‚æ•°
        prompt_wav_path = request.prompt_wav_path
        prompt_text = request.prompt_text
        
        if (prompt_wav_path is not None) != (prompt_text is not None):
            raise HTTPException(
                status_code=400, 
                detail="å‚è€ƒéŸ³é¢‘å’Œå‚è€ƒæ–‡æœ¬å¿…é¡»åŒæ—¶æä¾›æˆ–åŒæ—¶ä¸ºç©º"
            )
        
        if prompt_wav_path and not os.path.exists(prompt_wav_path):
            raise HTTPException(
                status_code=400,
                detail=f"å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {prompt_wav_path}"
            )
        
        print(f"æ­£åœ¨æµå¼ç”Ÿæˆè¯­éŸ³ï¼Œæ–‡æœ¬: '{text[:60]}...'")
        
        # è·å–é‡‡æ ·ç‡
        sample_rate = model.tts_model.sample_rate
        
        # æµå¼ç”Ÿæˆè¯­éŸ³
        def generate_audio_stream():
            try:
                # é¦–å…ˆå‘é€é‡‡æ ·ç‡ä¿¡æ¯ï¼ˆä½œä¸º JSON å…ƒæ•°æ®ï¼Œå¯é€‰ï¼‰
                # æˆ–è€…ç›´æ¥å¼€å§‹å‘é€éŸ³é¢‘æ•°æ®
                
                # ä½¿ç”¨æµå¼ç”Ÿæˆ
                for chunk in model.generate_streaming(
                    text=text,
                    prompt_text=prompt_text,
                    prompt_wav_path=prompt_wav_path,
                    cfg_value=request.cfg_value or 2.0,
                    inference_timesteps=request.inference_timesteps or 10,
                    normalize=request.normalize or False,
                    denoise=request.denoise or False,
                ):
                    # å°†éŸ³é¢‘å—è½¬æ¢ä¸º 16-bit PCM æ ¼å¼
                    # chunk æ˜¯ float32 æ ¼å¼ï¼ŒèŒƒå›´é€šå¸¸åœ¨ [-1, 1]
                    chunk_int16 = (chunk * 32767).astype(np.int16)
                    # è½¬æ¢ä¸ºå­—èŠ‚æµ
                    chunk_bytes = chunk_int16.tobytes()
                    yield chunk_bytes
                    
            except Exception as e:
                logging.error(f"æµå¼ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", exc_info=True)
                # æ³¨æ„ï¼šä¸€æ—¦å¼€å§‹æµå¼ä¼ è¾“ï¼Œæ— æ³•å‘é€ HTTP é”™è¯¯å“åº”
                # å¯ä»¥è€ƒè™‘å‘é€é”™è¯¯æ ‡è®°æˆ–è®°å½•æ—¥å¿—
                raise
        
        return StreamingResponse(
            generate_audio_stream(),
            media_type="audio/pcm",
            headers={
                "Content-Type": f"audio/pcm; rate={sample_rate}; channels=1; encoding=pcm_s16le",
                "X-Sample-Rate": str(sample_rate),
                "X-Channels": "1",
                "X-Encoding": "pcm_s16le",
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logging.error(f"æµå¼ç”Ÿæˆè¯­éŸ³æ—¶å‡ºé”™: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"æµå¼ç”Ÿæˆè¯­éŸ³å¤±è´¥: {str(e)}")


def run_server(host: str = "0.0.0.0", port: int = 8000):
    """è¿è¡Œ API æœåŠ¡å™¨"""
    print(f"æ­£åœ¨å¯åŠ¨ VoxCPM API æœåŠ¡å™¨...")
    print(f"æœåŠ¡åœ°å€: http://{host}:{port}")
    print(f"API æ–‡æ¡£: http://{host}:{port}/docs")
    print(f"å¥åº·æ£€æŸ¥: http://{host}:{port}/health")
    print(f"TTS ç«¯ç‚¹: http://{host}:{port}/tts")
    uvicorn.run(app, host=host, port=port)


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="VoxCPM TTS API Server for Legado Reader")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="æœåŠ¡å™¨ä¸»æœºåœ°å€")
    parser.add_argument("--port", type=int, default=8000, help="æœåŠ¡å™¨ç«¯å£")
    args = parser.parse_args()
    
    run_server(host=args.host, port=args.port)
